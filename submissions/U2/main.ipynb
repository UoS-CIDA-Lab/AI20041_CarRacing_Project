{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' #1\n",
    "import gymnasium as gym\n",
    "import matplotlib\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing(img):\n",
    "  img = cv2.resize(img, dsize=(84, 84))\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) / 255.0\n",
    "  return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarEnvironment(gym.Wrapper):\n",
    "  def __init__(self, env, skip_frames=2, stack_frames=4, no_operation=5, **kwargs):\n",
    "    super().__init__(env, **kwargs)\n",
    "    self._no_operation = no_operation\n",
    "    self._skip_frames = skip_frames\n",
    "    self._stack_frames = stack_frames\n",
    "\n",
    "  def reset(self):\n",
    "    observation, info = self.env.reset()\n",
    "\n",
    "    for i in range(self._no_operation):\n",
    "      observation, reward, terminated, truncated, info = self.env.step(0)\n",
    "\n",
    "    observation = image_preprocessing(observation)\n",
    "    self.stack_state = np.tile(observation, (self._stack_frames, 1, 1))\n",
    "    return self.stack_state, info\n",
    "\n",
    "\n",
    "  def step(self, action):\n",
    "    total_reward = 0\n",
    "    for i in range(self._skip_frames):\n",
    "      observation, reward, terminated, truncated, info = self.env.step(action)\n",
    "      total_reward += reward\n",
    "      if terminated or truncated:\n",
    "        break\n",
    "\n",
    "    observation = image_preprocessing(observation)\n",
    "    self.stack_state = np.concatenate((self.stack_state[1:], observation[np.newaxis]), axis=0)\n",
    "    return self.stack_state, total_reward, terminated, truncated, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self._n_features = 32 * 9 * 9\n",
    "\n",
    "    self.conv = nn.Sequential(\n",
    "        nn.Conv2d(in_channels, 16, kernel_size=8, stride=4),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Conv2d(16, 32, kernel_size=4, stride=2),\n",
    "        nn.LeakyReLU(),\n",
    "    )\n",
    "\n",
    "    self.fc = nn.Sequential(\n",
    "        nn.Linear(self._n_features, 256),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(256, out_channels),\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv(x)\n",
    "    x = x.view((-1, self._n_features))\n",
    "    x = self.fc(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory:\n",
    "  def __init__(self, capacity, alpha=0.6):\n",
    "    self.capacity = capacity\n",
    "    self.buffer = []\n",
    "    self.priorities = np.zeros((capacity,), dtype=np.float32)\n",
    "    self.alpha = alpha\n",
    "    self.pos = 0\n",
    "\n",
    "  def push(self, experience, priority=1.0):\n",
    "    max_priority = self.priorities.max() if self.buffer else 1.0\n",
    "    if len(self.buffer) < self.capacity:\n",
    "      self.buffer.append(Transition(*experience))\n",
    "    else:\n",
    "      self.buffer[self.pos] = Transition(*experience)\n",
    "    self.priorities[self.pos] = max(priority, max_priority)\n",
    "    self.pos = (self.pos + 1) % self.capacity\n",
    "\n",
    "  def sample(self, batch_size, beta=0.4):\n",
    "    if len(self.buffer) == self.capacity:\n",
    "      priorities = self.priorities\n",
    "    else:\n",
    "      priorities = self.priorities[:self.pos]\n",
    "\n",
    "    probabilities = priorities ** self.alpha\n",
    "    probabilities /= probabilities.sum()\n",
    "\n",
    "    indices = np.random.choice(len(self.buffer), batch_size, p=probabilities)\n",
    "    samples = [self.buffer[idx] for idx in indices]\n",
    "\n",
    "    weights = (len(self.buffer) * probabilities[indices]) ** (-beta)\n",
    "    weights /= weights.max()\n",
    "    return samples, indices, weights\n",
    "\n",
    "  def update_priorities(self, indices, priorities):\n",
    "    for idx, priority in zip(indices, priorities):\n",
    "      self.priorities[idx] = priority\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "  def __init__(self, action_space, batch_size=256, gamma=0.9, eps_start=0.99, eps_end=0.03, eps_decay=1000, lr=0.001, device=device):\n",
    "    self.device = device\n",
    "    self._n_observation = 4\n",
    "    self._n_actions = 5\n",
    "    self._action_space = action_space\n",
    "    self._batch_size = batch_size\n",
    "    self._gamma = gamma\n",
    "    self._eps_start = eps_start\n",
    "    self._eps_end = eps_end\n",
    "    self._eps_decay = eps_decay\n",
    "    self._lr = lr\n",
    "    self._total_steps = 0\n",
    "    self._evaluate_loss = []\n",
    "    self.network = CNN(self._n_observation, self._n_actions).to(self.device)\n",
    "    self.target_network = CNN(self._n_observation, self._n_actions).to(self.device)\n",
    "    self.target_network.load_state_dict(self.network.state_dict())\n",
    "    self.optimizer = optim.AdamW(self.network.parameters(), lr=self._lr, amsgrad=True)\n",
    "    self._memory = ReplayMemory(100000)\n",
    "\n",
    "  \"\"\"\n",
    "  This function is called during training & evaluation phase when the agent\n",
    "  interact with the environment and needs to select an action.\n",
    "\n",
    "  (1) Exploitation: This function feeds the neural network a state\n",
    "  and then it selects the action with the highest Q-value.\n",
    "  (2) Evaluation mode: This function feeds the neural network a state\n",
    "  and then it selects the action with the highest Q'-value.\n",
    "  (3) Exploration mode: It randomly selects an action through sampling\n",
    "\n",
    "  Q -> network (policy)\n",
    "  Q'-> target network (best policy)\n",
    "  \"\"\"\n",
    "  def select_action(self, state, evaluation_phase=False):\n",
    "\n",
    "    # Generating a random number for exploration vs exploitation\n",
    "    sample = random.random()\n",
    "\n",
    "    # Calculating the threshold - the more steps the less exploration we do\n",
    "    eps_threshold = self._eps_end + (self._eps_start - self._eps_end) * math.exp(-1. * self._total_steps / self._eps_decay)\n",
    "    self._total_steps += 1\n",
    "\n",
    "    if evaluation_phase:\n",
    "      with torch.no_grad():\n",
    "        return self.target_network(state).max(1).indices.view(1, 1)\n",
    "    elif sample > eps_threshold:\n",
    "      with torch.no_grad():\n",
    "        return self.network(state).max(1).indices.view(1, 1)\n",
    "    else:\n",
    "      return torch.tensor([[self._action_space.sample()]], device=self.device, dtype=torch.long)\n",
    "\n",
    "  def train(self):\n",
    "\n",
    "    if len(self._memory) < self._batch_size:\n",
    "        return\n",
    "\n",
    "    # Initializing our memory\n",
    "    transitions, indices, weights = self._memory.sample(self._batch_size)\n",
    "\n",
    "    # Initializing our batch\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Saving in a new tensor all the indices of the states that are non terminal\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=self.device, dtype=torch.bool)\n",
    "\n",
    "    # Saving in a new tensor all the non final next states\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Feeding our Q network the batch with states and then we gather the Q values of the selected actions\n",
    "    state_action_values = self.network(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # We then, for every state in the batch that is NOT final, we pass it in the target network to get the Q'-values and choose the max one\n",
    "    next_state_values = torch.zeros(self._batch_size, device=self.device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = self.target_network(non_final_next_states).max(1).values\n",
    "\n",
    "    # Computing the expecting values with: reward + gamma * max(Q')\n",
    "    expected_state_action_values = (next_state_values * self._gamma) + reward_batch\n",
    "\n",
    "    # Defining our loss criterion\n",
    "    criterion = nn.SmoothL1Loss(reduction='none')\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    weights_tensor = torch.tensor(weights, device=self.device, requires_grad=True)\n",
    "    weighted_loss = (loss * weights_tensor).mean()\n",
    "\n",
    "    # Updating with back propagation\n",
    "    self.optimizer.zero_grad()\n",
    "    weighted_loss.backward()\n",
    "\n",
    "    torch.nn.utils.clip_grad_value_(self.network.parameters(), 100)\n",
    "    self.optimizer.step()\n",
    "\n",
    "    self._evaluate_loss.append(weighted_loss.item())\n",
    "\n",
    "    # Update priorities in the memory\n",
    "    priorities = loss.detach().cpu().numpy() + 1e-5\n",
    "    self._memory.update_priorities(indices, priorities)\n",
    "\n",
    "    return\n",
    "\n",
    "  def copy_weights(self):\n",
    "    self.target_network.load_state_dict(self.network.state_dict())\n",
    "\n",
    "  def get_loss(self):\n",
    "    return self._evaluate_loss\n",
    "\n",
    "  def save_model(self, i):\n",
    "    torch.save(self.target_network.state_dict(), f'model_weights_{i}.pth')\n",
    "\n",
    "  def load_model(self, i):\n",
    "    self.target_network.load_state_dict(torch.load(f'model_weights_{i}.pth', map_location=self.device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 episodes done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m count():\n\u001b[1;32m     25\u001b[0m   action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mselect_action(state)\n\u001b[0;32m---> 26\u001b[0m   observation, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m   reward \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([reward], device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     28\u001b[0m   episode_total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m, in \u001b[0;36mCarEnvironment.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     20\u001b[0m total_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip_frames):\n\u001b[0;32m---> 22\u001b[0m   observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m   total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m     24\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rl/lib/python3.10/site-packages/gymnasium/wrappers/common.py:121\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[1;32m    110\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[ObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rl/lib/python3.10/site-packages/gymnasium/wrappers/common.py:408\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rl/lib/python3.10/site-packages/gymnasium/core.py:317\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[1;32m    315\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    316\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rl/lib/python3.10/site-packages/gymnasium/wrappers/common.py:300\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rl/lib/python3.10/site-packages/gymnasium/envs/box2d/car_racing.py:561\u001b[0m, in \u001b[0;36mCarRacing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mStep(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS, \u001b[38;5;241m6\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS\n\u001b[0;32m--> 561\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_pixels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m step_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    564\u001b[0m terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rl/lib/python3.10/site-packages/gymnasium/envs/box2d/car_racing.py:655\u001b[0m, in \u001b[0;36mCarRacing._render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_image_array(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, (VIDEO_W, VIDEO_H))\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_pixels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 655\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msurf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mSTATE_W\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTATE_H\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misopen\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rl/lib/python3.10/site-packages/gymnasium/envs/box2d/car_racing.py:786\u001b[0m, in \u001b[0;36mCarRacing._create_image_array\u001b[0;34m(self, screen, size)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_image_array\u001b[39m(\u001b[38;5;28mself\u001b[39m, screen, size):\n\u001b[0;32m--> 786\u001b[0m     scaled_screen \u001b[38;5;241m=\u001b[39m \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmoothscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscreen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mtranspose(\n\u001b[1;32m    788\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(pygame\u001b[38;5;241m.\u001b[39msurfarray\u001b[38;5;241m.\u001b[39mpixels3d(scaled_screen)), axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    789\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rewards_per_episode = []\n",
    "episode_duration = []\n",
    "average_episode_loss = []\n",
    "\n",
    "episodes = 1000\n",
    "C = 5\n",
    "\n",
    "env = gym.make('CarRacing-v2', lap_complete_percent=0.95, continuous=False)\n",
    "n_actions = env.action_space\n",
    "agent = DQN(n_actions)\n",
    "\n",
    "for episode in range(1, episodes + 1):\n",
    "  print(f\"{episode} episodes done\")\n",
    "\n",
    "  env = gym.make('CarRacing-v2', continuous=False)\n",
    "  env = CarEnvironment(env)\n",
    "\n",
    "  state, info = env.reset()\n",
    "\n",
    "  state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "  episode_total_reward = 0\n",
    "\n",
    "  for t in count():\n",
    "    action = agent.select_action(state)\n",
    "    observation, reward, terminated, truncated, _ = env.step(action.item())\n",
    "    reward = torch.tensor([reward], device=device)\n",
    "    episode_total_reward += reward\n",
    "    done = terminated or truncated\n",
    "\n",
    "    if terminated:\n",
    "      next_state = None\n",
    "      print(\"Finished the lap successfully!\")\n",
    "    else:\n",
    "      next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "    agent._memory.push((state, action, next_state, reward))\n",
    "\n",
    "    state = next_state\n",
    "\n",
    "    agent.train()\n",
    "\n",
    "    if done:\n",
    "      if agent._memory.__len__() >= 128:\n",
    "        episode_duration.append(t + 1)\n",
    "        rewards_per_episode.append(episode_total_reward)\n",
    "        ll = agent.get_loss()\n",
    "        average_episode_loss.append(sum(ll) / len(ll))\n",
    "      break\n",
    "\n",
    "    if episode % 10 == 0:\n",
    "      agent.save_model(episode)\n",
    "      with open('statistics.pkl', 'wb') as f:\n",
    "        pickle.dump((episode_duration, rewards_per_episode, average_episode_loss), f)\n",
    "\n",
    "  if episode % C == 0:\n",
    "    agent.copy_weights()\n",
    "\n",
    "agent.save_model(episodes)\n",
    "with open('statistics.pkl', 'wb') as f:\n",
    "  pickle.dump((episode_duration, rewards_per_episode, average_episode_loss), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_statistics(x, y, title, x_axis, y_axis):\n",
    "  plt.plot(x, y)\n",
    "  plt.xlabel(x_axis)\n",
    "  plt.ylabel(y_axis)\n",
    "  plt.title(title)\n",
    "  plt.grid(True)\n",
    "  plt.savefig(f'{title.replace(\" \", \"_\")}.png')  # 공백 대신 밑줄 사용\n",
    "  plt.show()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ny/vfq7pz4n15q5tx9pbk4ynxp40000gn/T/ipykernel_17275/1884895254.py:115: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.target_network.load_state_dict(torch.load(f'model_weights_{i}.pth', map_location=self.device))\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=600x400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902.9210526315658\n"
     ]
    }
   ],
   "source": [
    "eval_env = gym.make('CarRacing-v2', continuous=False, render_mode='rgb_array')\n",
    "eval_env = CarEnvironment(eval_env)\n",
    "n_actions = eval_env.action_space\n",
    "agent = DQN(n_actions, device=\"cpu\")\n",
    "agent.load_model(370)\n",
    "\n",
    "frames = []\n",
    "scores = 0\n",
    "s, _ = eval_env.reset()\n",
    "\n",
    "eval_env.np_random = np.random.default_rng(42)\n",
    "\n",
    "done, ret = False, 0\n",
    "\n",
    "from PIL import Image as PILImage\n",
    "def render2img(_img): return PILImage.fromarray(_img, \"RGB\")\n",
    "handle = display(None, display_id=True)\n",
    "while not done:\n",
    "    _render = eval_env.render()\n",
    "    handle.update(render2img(_render))\n",
    "    frames.append(_render)\n",
    "    s = torch.tensor(s, dtype=torch.float32, device=\"cpu\").unsqueeze(0)\n",
    "    a = agent.select_action(s, evaluation_phase=True)\n",
    "    discrete_action = a.item() % 5\n",
    "    s_prime, r, terminated, truncated, info = eval_env.step(discrete_action)\n",
    "    s = s_prime\n",
    "    ret += r\n",
    "    done = terminated or truncated\n",
    "    if terminated:\n",
    "      print(terminated)\n",
    "      \n",
    "scores += ret\n",
    "\n",
    "print(scores)\n",
    "def animate(imgs, video_name, _return=True):\n",
    "    import cv2\n",
    "    import os\n",
    "    import string\n",
    "    import random\n",
    "\n",
    "    if video_name is None:\n",
    "        video_name = ''.join(random.choice(string.ascii_letters) for i in range(18)) + '.webm'\n",
    "    height, width, layers = imgs[0].shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'VP90')\n",
    "    video = cv2.VideoWriter(video_name, fourcc, 10, (width, height))\n",
    "\n",
    "    for img in imgs:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        video.write(img)\n",
    "    video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x30395056/'VP90' is not supported with codec id 167 and format 'webm / WebM'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m animate(frames, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatistics.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 4\u001b[0m     data_tuple \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m episode_duration, rewards_per_episode, average_episode_loss \u001b[38;5;241m=\u001b[39m data_tuple\n\u001b[1;32m      8\u001b[0m x \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(episode_duration))]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rl/lib/python3.10/site-packages/torch/storage.py:414\u001b[0m, in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_from_bytes\u001b[39m(b):\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rl/lib/python3.10/site-packages/torch/serialization.py:1114\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1113\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rl/lib/python3.10/site-packages/torch/serialization.py:1348\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1347\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1348\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m deserialized_storage_keys \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_guards\u001b[38;5;241m.\u001b[39mactive_fake_mode() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rl/lib/python3.10/site-packages/torch/serialization.py:1281\u001b[0m, in \u001b[0;36m_legacy_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1279\u001b[0m     obj \u001b[38;5;241m=\u001b[39m cast(Storage, torch\u001b[38;5;241m.\u001b[39mUntypedStorage(nbytes))\n\u001b[1;32m   1280\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_torch_load_uninitialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1281\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m   1285\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39mobj,\n\u001b[1;32m   1286\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1287\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rl/lib/python3.10/site-packages/torch/serialization.py:414\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 414\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rl/lib/python3.10/site-packages/torch/serialization.py:391\u001b[0m, in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    389\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_privateuse1_backend_name()\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[0;32m--> 391\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/rl/lib/python3.10/site-packages/torch/serialization.py:364\u001b[0m, in \u001b[0;36m_validate_device\u001b[0;34m(location, backend_name)\u001b[0m\n\u001b[1;32m    362\u001b[0m     device_index \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_available\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    365\u001b[0m                        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    366\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    367\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    368\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice_count\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    370\u001b[0m     device_count \u001b[38;5;241m=\u001b[39m device_module\u001b[38;5;241m.\u001b[39mdevice_count()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "animate(frames, None)\n",
    "\n",
    "with open('statistics.pkl', 'rb') as f:\n",
    "    data_tuple = pickle.load(f)\n",
    "\n",
    "episode_duration, rewards_per_episode, average_episode_loss = data_tuple\n",
    "\n",
    "x = [k for k in range(len(episode_duration))]\n",
    "\n",
    "rewards_per_episode = [tensor.cpu() if tensor.is_cuda else tensor for tensor in rewards_per_episode]\n",
    "\n",
    "plot_statistics(x, rewards_per_episode, \"Rewards for every episode\", \"Episode\", \"Reward\")\n",
    "plot_statistics(x, average_episode_loss, \"Average loss for every episode\", \"Episode\", \"Average Loss\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
